{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5ecd807-fb1c-41eb-a948-365e57396d90",
   "metadata": {},
   "source": [
    "# Level 6: Agents, MCP and RAG \n",
    "\n",
    "This notebook is an extension of the [Level 5 Agentic & MCP notebook](./Level5_agents_and_mcp.ipynb) with the addition of RAG.\n",
    "This tutorial is for developers who are already familiar with [agentic RAG workflows](./Level4_RAG_agent.ipynb). This tutorial will highlight a couple of slightly more advanced use cases for agents where a single tool call is insufficient to complete the required task. Here we will rely on both agentic RAG and MCP server to expand our agents capabilities.\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial covers the following steps:\n",
    "1. Review OpenShift logs for a failing pod.\n",
    "2. Categorize the pod and summarize its error.\n",
    "3. Search available troubleshooting documentations for ideas on how to resolve the error.\n",
    "4. Send a Slack message to the ops team with a brief summary of the error and next steps to take.\n",
    "\n",
    "### MCP Tools:\n",
    "\n",
    "#### OpenShift MCP Server\n",
    "Throughout this notebook we will be relying on the [kubernetes-mcp-server](https://github.com/manusa/kubernetes-mcp-server) by [manusa](https://github.com/manusa) to interact with our OpenShift cluster. Please see installation instructions below if you do not already have this deployed in your environment. \n",
    "\n",
    "* [OpenShift MCP installation instructions](../../../kubernetes/mcp-servers/openshift-mcp/README.md)\n",
    "\n",
    "#### Slack MCP Server\n",
    "We will also be using the [Slack MCP Server](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/slack) in this notebook. Please see installation instructions below if you do not already have this deployed in your environment. \n",
    "\n",
    "* [Slack MCP installation instructions](../../../kubernetes/mcp-servers/slack-mcp/README.md)\n",
    "\n",
    "### Pre-Requisites\n",
    "\n",
    "Before starting, ensure you have the following:\n",
    "- A running Llama Stack server\n",
    "- A running Slack MCP server. Refer to our [documentation](https://github.com/opendatahub-io/llama-stack-demos/tree/main/kubernetes/mcp-servers/slack-mcp) on how you can set this up on your OpenShift cluster\n",
    "- Access to an OpeShift cluster with a deployment of the [OpenShift MCP server](../../../kubernetes/mcp-servers/openshift-mcp) (see the [deployment manifests](https://github.com/opendatahub-io/llama-stack-on-ocp/tree/main/kubernetes/mcp-servers/openshift-mcp) for assistance with this).\n",
    "\n",
    "## Setting Up this Notebook\n",
    "We will initialize our environment as described in detail in our [\\\"Getting Started\\\" notebook](./Level0_getting_started_with_Llama_Stack.ipynb). Please refer to it for additional explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25fc0a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for communication with Llama Stack\n",
    "from llama_stack_client import LlamaStackClient\n",
    "from llama_stack_client import Agent\n",
    "from llama_stack_client.lib.agents.event_logger import EventLogger\n",
    "from llama_stack_client import RAGDocument\n",
    "from llama_stack_client.lib.agents.react.agent import ReActAgent\n",
    "from llama_stack_client.lib.agents.react.tool_parser import ReActOutput\n",
    "\n",
    "# pretty print of the results returned from the model/agent\n",
    "from termcolor import cprint\n",
    "import sys\n",
    "sys.path.append('..')  \n",
    "from src.utils import step_printer\n",
    "import uuid\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08281062-f222-4443-a7bc-0f6166aab36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Llama Stack server\n",
      "Inference Parameters:\n",
      "\tModel: qwen\n",
      "\tSampling Parameters: {'strategy': {'type': 'greedy'}, 'max_tokens': 2048}\n",
      "\tstream: False\n"
     ]
    }
   ],
   "source": [
    "base_url = os.getenv(\"REMOTE_BASE_URL\")\n",
    "\n",
    "\n",
    "# Tavily search API key is required for some of our demos and must be provided to the client upon initialization.\n",
    "# We will cover it in the agentic demos that use the respective tool. Please ignore this parameter for all other demos.\n",
    "tavily_search_api_key = os.getenv(\"TAVILY_SEARCH_API_KEY\")\n",
    "if tavily_search_api_key is None:\n",
    "    provider_data = None\n",
    "else:\n",
    "    provider_data = {\"tavily_search_api_key\": tavily_search_api_key}\n",
    "\n",
    "\n",
    "client = LlamaStackClient(\n",
    "    base_url=base_url,\n",
    "    provider_data=provider_data\n",
    ")\n",
    "\n",
    "print(f\"Connected to Llama Stack server\")\n",
    "\n",
    "# model_id will later be used to pass the name of the desired inference model to Llama Stack Agents/Inference APIs\n",
    "# model_id = \"granite\"\n",
    "model_id = \"qwen\"\n",
    "\n",
    "temperature = float(os.getenv(\"TEMPERATURE\", 0.0))\n",
    "if temperature > 0.0:\n",
    "    top_p = float(os.getenv(\"TOP_P\", 0.95))\n",
    "    strategy = {\"type\": \"top_p\", \"temperature\": temperature, \"top_p\": top_p}\n",
    "else:\n",
    "    strategy = {\"type\": \"greedy\"}\n",
    "\n",
    "max_tokens = int(os.getenv(\"MAX_TOKENS\", 512))\n",
    "\n",
    "# sampling_params will later be used to pass the parameters to Llama Stack Agents/Inference APIs\n",
    "sampling_params = {\n",
    "    \"strategy\": strategy,\n",
    "    \"max_tokens\": max_tokens,\n",
    "}\n",
    "\n",
    "# For this demo, we are using Milvus Lite, which is our preferred solution. Any other Vector DB supported by Llama Stack can be used.\n",
    "\n",
    "# RAG vector DB settings\n",
    "VECTOR_DB_EMBEDDING_MODEL = os.getenv(\"VDB_EMBEDDING\")\n",
    "VECTOR_DB_EMBEDDING_DIMENSION = int(os.getenv(\"VDB_EMBEDDING_DIMENSION\", 384))\n",
    "VECTOR_DB_CHUNK_SIZE = int(os.getenv(\"VECTOR_DB_CHUNK_SIZE\", 512))\n",
    "VECTOR_DB_PROVIDER_ID = os.getenv(\"VDB_PROVIDER\")\n",
    "\n",
    "# Unique DB ID for session\n",
    "vector_db_id = f\"test_vector_db_{uuid.uuid4()}\"\n",
    "\n",
    "stream_env = os.getenv(\"STREAM\", \"False\")\n",
    "# the Boolean 'stream' parameter will later be passed to Llama Stack Agents/Inference APIs\n",
    "# any value non equal to 'False' will be considered as 'True'\n",
    "stream = (stream_env != \"False\")\n",
    "\n",
    "print(f\"Inference Parameters:\\n\\tModel: {model_id}\\n\\tSampling Parameters: {sampling_params}\\n\\tstream: {stream}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66044170",
   "metadata": {},
   "source": [
    "### Validate tools are available in our Llama Stack instance\n",
    "\n",
    "We will be using the [OpenShift MCP Server](https://github.com/manusa/kubernetes-mcp-server) and the [Slack MCP Server](https://github.com/modelcontextprotocol/servers/tree/main/src/slack) for performing this task. If you haven't already, you can follow the instructions [here](https://github.com/opendatahub-io/llama-stack-demos/tree/main/kubernetes/mcp-servers/slack-mcp#setting-up-on-ocp) to install the Slack MCP server and the instructions [here](https://github.com/opendatahub-io/llama-stack-demos/tree/main/kubernetes/mcp-servers/openshift-mcp#steps-for-deploying-the-openshift-mcp-server-on-openshift) to install the OpenShift MCP server. Once we confirm that the OpenShift and Slack MCP servers are running and configured to your Llama Stack server, we can then move on to defining an agent to help with our task.\n",
    "\n",
    "#### Registering tools on Llama Stack\n",
    "When an instance of llama stack is redeployed your tools need to re-registered. Also if a tool is already registered with a llama stack instance, if you try to register one with the same `toolgroup_id`, llama stack will throw you an error.\n",
    "\n",
    "For this reason it is recommended to include some code to validate your tools and toolgroups. This is where the `mcp_url` comes into play. The following code will check that the `builtin::rag`,`mcp::openshift`  and `mcp::slack` tools are registered as tools, but if any mcp tool is not listed there, it will attempt to register it using the mcp url.\n",
    "\n",
    "If you are running the MCP server from source, the default value for this is: `http://localhost:8000/sse`.\n",
    "\n",
    "If you are running the MCP server from a container, the default value for this is: `http://host.containers.internal:8000/sse`.\n",
    "\n",
    "Make sure to pass the corresponding MCP URL for the server you are trying to register/validate tools for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b2cedaf-522b-4251-886a-d8aa7b9fcd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://llamastack:8321/v1/tools \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Llama Stack server is already registered with the following tool groups: {'builtin::websearch', 'mcp::slack', 'mcp::openshift', 'builtin::rag', 'builtin::math'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Optional: Enter your MCP server URL here\n",
    "ocp_mcp_url = os.getenv(\"REMOTE_OCP_MCP_URL\") # Optional: enter your MCP server url here\n",
    "slack_mcp_url = os.getenv(\"REMOTE_SLACK_MCP_URL\") # Optional: enter your MCP server url here\n",
    "\n",
    "# Get list of registered tools and extract their toolgroup IDs\n",
    "registered_tools = client.tools.list()\n",
    "registered_toolgroups = [tool.toolgroup_id for tool in registered_tools]\n",
    "\n",
    "if  \"builtin::rag\" not in registered_toolgroups: # Required\n",
    "    client.toolgroups.register(\n",
    "        toolgroup_id=\"builtin::rag\",\n",
    "        provider_id=\"milvus\"\n",
    "    )\n",
    "\n",
    "if \"mcp::openshift\" not in registered_toolgroups: # required\n",
    "    client.toolgroups.register(\n",
    "        toolgroup_id=\"mcp::openshift\",\n",
    "        provider_id=\"model-context-protocol\",\n",
    "        mcp_endpoint={\"uri\":ocp_mcp_url},\n",
    "    )\n",
    "\n",
    "if \"mcp::slack\" not in registered_toolgroups: # required\n",
    "    client.toolgroups.register(\n",
    "        toolgroup_id=\"mcp::slack\",\n",
    "        provider_id=\"model-context-protocol\",\n",
    "        mcp_endpoint={\"uri\":slack_mcp_url},\n",
    "    )\n",
    "\n",
    "# Log the current toolgroups registered\n",
    "print(f\"Your Llama Stack server is already registered with the following tool groups: {set(registered_toolgroups)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc8d3f8",
   "metadata": {},
   "source": [
    "## Discover and report solutions to errors that might be happening on my OpenShift Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f6993e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "We will now try to use an agent to:\n",
    "- **Retrieve the logs of a failing pod running on OpenShift**\n",
    "- **Use RAG to find solutions to the errors in the pod logs based on OpenShift troubleshooting documents**\n",
    "- **Send a summary of the solution as a message on Slack.**\n",
    "\n",
    "### Pod with simulated error logs\n",
    "\n",
    "**Important** - In the [Level5 Agents and MCP notebook](./Level5_agents_and_mcp.ipynb) we deployed a pod called `slack-test` on an OpenShift cluster that generates simulated error logs. For the purpose of testing the pod log retrieval, we will be using that pod for this notebook and assume that it is already running on your cluster. **If you haven't already, please make sure to go through the Level5 notebook before continuing this notebook.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85664f8",
   "metadata": {},
   "source": [
    "### RAG: Indexing the Documents\n",
    "\n",
    "We will be leveraging RAG to help us find solutions from OpenShift troubleshooting documents for debugging the logs of erroneous pods running on OpenShift. We will need to:\n",
    "- Initialize a new document collection in the target vector DB. All parameters related to the vector DB, such as the embedding model and dimension, must be specified here.\n",
    "- Provide a list of document URLs to the RAG tool. Llama Stack will handle fetching, conversion and chunking of the documents' content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a8f4dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://llamastack:8321/v1/vector-dbs \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://llamastack:8321/v1/tool-runtime/rag-tool/insert \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# define and register the document collection to be used\n",
    "client.vector_dbs.register(\n",
    "    vector_db_id=vector_db_id,\n",
    "    embedding_model=VECTOR_DB_EMBEDDING_MODEL,\n",
    "    embedding_dimension=VECTOR_DB_EMBEDDING_DIMENSION,\n",
    "    provider_id=VECTOR_DB_PROVIDER_ID,\n",
    ")\n",
    "\n",
    "# ingest the documents into the newly created document collection\n",
    "urls = [\n",
    "    (\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.11/pdf/support/OpenShift_Container_Platform-4.11-Support-en-US.pdf\", \"application/pdf\"),\n",
    "]\n",
    "documents = [\n",
    "    RAGDocument(\n",
    "        document_id=f\"num-{i}\",\n",
    "        content=url,\n",
    "        mime_type=url_type,\n",
    "        metadata={},\n",
    "    )\n",
    "    for i, (url, url_type) in enumerate(urls)\n",
    "]\n",
    "client.tool_runtime.rag_tool.insert(\n",
    "    documents=documents,\n",
    "    vector_db_id=vector_db_id,\n",
    "    chunk_size_in_tokens=VECTOR_DB_CHUNK_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf70ace-b704-4379-aa88-3c793cc4f959",
   "metadata": {},
   "source": [
    "### System Prompt for LLM model\n",
    "\n",
    "**Note:** If you have multiple models configured with your Llama Stack server, you can choose which one to run your queries against. When switching to a different model, you may need to adjust the system prompt to align with that model’s expected behavior. Many models provide recommended system prompts for optimal and reliable outputs these are typically documented on their respective websites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3136e6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prompt= \"\"\"You are a helpful assistant. You have access to a number of tools.\n",
    "Whenever a tool is called, be sure return the Response in a friendly and helpful tone.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b675f2a",
   "metadata": {},
   "source": [
    "## Defining our Agent - Prompt Chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b340e517",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://llamastack:8321/v1/agents \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://llamastack:8321/v1/tools?toolgroup_id=builtin%3A%3Arag \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://llamastack:8321/v1/tools?toolgroup_id=mcp%3A%3Aopenshift \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://llamastack:8321/v1/tools?toolgroup_id=mcp%3A%3Aslack \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://llamastack:8321/v1/agents/77a2c618-2f48-49b8-b688-a4de3ff6d904/session \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://llamastack:8321/v1/agents/77a2c618-2f48-49b8-b688-a4de3ff6d904/session/9c1cc0d9-8f74-4fff-9ac7-8967e7add797/turn \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- 📍 Step 1: InferenceStep ----------\n",
      "🛠️ Tool call Generated:\n",
      "\u001b[35mTool call: pods_log, Arguments: {'name': 'slack-test', 'namespace': 'llama-serve'}\u001b[0m\n",
      "\n",
      "---------- 📍 Step 2: ToolExecutionStep ----------\n",
      "🔧 Executing tool...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Starting container...\\nFailure: Unknown Error\\nError details: Container failed due to an unexpected issue during startup.\\nPotential cause: Missing dependencies, configuration errors, or permission issues.\\n'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'annotations'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'text'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'text'\u001b[0m: \u001b[32m'Starting container...\\nFailure: Unknown Error\\nError details: Container failed due to an unexpected issue during startup.\\nPotential cause: Missing dependencies, configuration errors, or permission issues.\\n'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'annotations'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://llamastack:8321/v1/agents/77a2c618-2f48-49b8-b688-a4de3ff6d904/session/9c1cc0d9-8f74-4fff-9ac7-8967e7add797/turn \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- 📍 Step 3: InferenceStep ----------\n",
      "🤖 Model Response:\n",
      "\u001b[35m<think>\n",
      "Okay, let's see. The user asked to view the logs for the pod named \"slack-test\" in the \"llama-serve\" namespace and categorize them as normal or error.\n",
      "\n",
      "First, I need to call the pods_log function with the given name and namespace. The response from the tool shows some log entries. The logs start with \"Starting container...\" which is a normal part of the process. But then there's \"Failure: Unknown Error\" and details about the container failing. The potential causes mentioned are missing dependencies, configuration errors, or permission issues.\n",
      "\n",
      "So, the logs contain both a starting message (normal) and an error message. However, the presence of a failure indicates that the main issue here is an error. The user wants the logs categorized, so even though there's a starting message, the overall category should be error because the pod failed to start properly. I need to present the logs and then clearly state that it's categorized as an error, explaining the reasons based on the log content.\n",
      "</think>\n",
      "\n",
      "The logs for the pod `slack-test` in the `llama-serve` namespace are as follows:\n",
      "\n",
      "```\n",
      "Starting container...\n",
      "Failure: Unknown Error\n",
      "Error details: Container failed due to an unexpected issue during startup.\n",
      "Potential cause: Missing dependencies, configuration errors, or permission issues.\n",
      "```\n",
      "\n",
      "**Categorization:** **Error**  \n",
      "The logs indicate a failure during container startup, likely due to missing dependencies, configuration issues, or permissions problems. The \"Unknown Error\" suggests an unresolved problem requiring further investigation.\n",
      "\u001b[0m\n",
      "========== Query processing completed ========== \n",
      "\n",
      "\n",
      "---------- 📍 Step 1: InferenceStep ----------\n",
      "🛠️ Tool call Generated:\n",
      "\u001b[35mTool call: knowledge_search, Arguments: {'query': 'Kubernetes pod startup failure unknown error missing dependencies configuration errors permission issues'}\u001b[0m\n",
      "\n",
      "---------- 📍 Step 2: ToolExecutionStep ----------\n",
      "🔧 Executing tool...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'knowledge_search tool found 5 chunks:\\nBEGIN of knowledge_search tool results.\\n'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Result 1\\nContent:  period. This attribute defaults at 30 seconds,\\nbut can be customized for each application as necessary. If set to more than 90\\nseconds, the pod might be marked as \\nSIGKILLed\\n and fail to terminate\\nsuccessfully.\\n3\\n. \\nWhen the node returns, connect back to the node via SSH or Console. Then connect to the root\\nuser:\\n4\\n. \\nManually stop the kubelet:\\n5\\n. \\nStop the containers and pods:\\na\\n. \\nUse the following command to stop the pods that are not in the \\nHostNetwork\\n. They must\\nbe removed first because their removal relies on the networking plugin pods, which are in\\nthe \\nHostNetwork\\n.\\ncan\\'t stat lower layer ...  because it does not exist.  Going through storage to recreate the\\n \\nmissing symlinks.\\n$ oc adm cordon &lt;node_name&gt;\\n$ oc adm drain &lt;node_name&gt; --ignore-daemonsets --delete-emptydir-data\\n$ ssh core@node1.example.com\\n$ sudo -i\\n# systemctl stop kubelet\\nOpenShift Container Platform 4.11 Support\\n90\\nb\\n. \\nStop all other pods:\\n6\\n. \\nManually stop the crio services:\\n7\\n. \\nAfter you run those commands, you can completely wipe the ephemeral storage:\\n8\\n. \\nStart the crio and kubelet service:\\n9\\n. \\nYou will know if the clean up worked if the crio and kubelet services are started, and the node is\\nin the \\nReady\\n status:\\nExample output\\n10\\n. \\nMark the node schedulable. You will know that the scheduling is enabled when \\nSchedulingDisabled\\n is no longer in status:\\nExample output\\n7.4. TROUBLESHOOTING OPERATING SYSTEM ISSUES\\nOpenShift Container Platform runs on RHCOS. You can follow these procedures to troubleshoot\\nproblems related to the operating system.\\n7.4.1. Investigating kernel crashes\\nThe \\nkdump\\n service, included in the \\nkexec-tools\\n package, provides a crash-dumping mechanism. You\\ncan use this service to save the contents of a system’s memory for later analysis.\\nThe \\nx86_64\\n architecture supports kdump in General Availability (GA) status, whereas other\\n.. for pod in $(crictl pods -q); do if [[ \"$(crictl inspectp $pod | jq -r\\n \\n.status.linux.namespaces.options.network)\" != \"\\nMetadata: {\\'document_id\\': \\'num-0\\'}\\n'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Result 2\\nContent: . \\nList pods running within the namespace, as well as pod status, error states, restarts, and age:\\n3\\n. \\nDetermine whether the namespace is managed by a deployment configuration:\\nIf the namespace is managed by a deployment configuration, the output includes the\\ndeployment configuration name and a base image reference.\\n4\\n. \\nInspect the base image referenced in the preceding command’s output:\\n5\\n. \\nIf the base image reference is not correct, update the reference in the deployment\\nconfiguration:\\n6\\n. \\nWhen deployment configuration changes on exit, the configuration will automatically redeploy.\\nWatch pod status as the deployment progresses, to determine whether the issue has been\\nresolved:\\n7\\n. \\nReview events within the namespace for diagnostic information relating to pod failures:\\n7.7.3. Inspecting pod and container logs\\nYou can inspect pod and container logs for warnings and error messages related to explicit pod failures.\\nDepending on policy and exit code, pod and container logs remain available after pods have been\\nterminated.\\nPrerequisites\\nYou have access to the cluster as a user with the \\ncluster-admin\\n role.\\nYour API service is still functional.\\nYou have installed the OpenShift CLI (\\noc\\n).\\nProcedure\\n1\\n. \\nQuery logs for a specific pod:\\n2\\n. \\nQuery logs for a specific container within a pod:\\n$ oc get pods\\n$ oc status\\n$ skopeo inspect docker://&lt;image_reference&gt;\\n$ oc edit deployment/my-deployment\\n$ oc get pods -w\\n$ oc get events\\n$ oc logs &lt;pod_name&gt;\\nOpenShift Container Platform 4.11 Support\\n118\\nLogs retrieved using the preceding \\noc logs\\n commands are composed of messages sent to\\nstdout within pods or containers.\\n3\\n. \\nInspect logs contained in \\n/var/log/\\n within a pod.\\na\\n. \\nList log files and subdirectories contained in \\n/var/log\\n within a pod:\\nExample output\\nb\\n. \\nQuery a specific log file contained in \\n/var/log\\n within a pod:\\nExample output\\nc\\n. \\nList log files and subdirectories contained in \\n/var/log\\n within a specific container:\\nd\\n. \\nQuery a specific log file contained in \\n/var/log\\n within a specific container:\\n$ oc logs &lt;pod_name&gt; -c &lt;container_name&gt;\\n$ oc exec &lt;pod_name&gt;  -- ls -alh /var/log\\ntotal 124K\\ndrwxr-xr-x. 1 root root   33 Aug 11 11:23 .\\n\\nMetadata: {'document_id': 'num-0'}\\n\"</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Result 3\\nContent:  the \\nopenshift-sdn\\n namespace:\\nc\\n. \\nReview logs relating to failed OpenShift Container Platform SDN pods in the \\nopenshift-\\nsdn\\n namespace:\\n7\\n. \\nDetermine cluster network configuration status.\\na\\n. \\nReview whether the cluster’s network configuration exists:\\nb\\n. \\nIf the installer failed to create the network configuration, generate the Kubernetes\\nmanifests again and review message output:\\nc\\n. \\nReview the pod status in the \\nopenshift-network-operator\\n namespace to determine\\nwhether the Cluster Network Operator (CNO) is running:\\nd\\n. \\nGather network Operator pod logs from the \\nopenshift-network-operator\\n namespace:\\n8\\n. \\nMonitor \\nkubelet.service\\n journald unit logs on control plane nodes, after they have booted. This\\n$ oc get nodes\\n$ oc describe node &lt;master_node&gt;\\n$ oc get daemonsets -n openshift-sdn\\n$ oc get pods -n openshift-sdn\\n$ oc logs &lt;sdn_pod&gt; -n openshift-sdn\\n$ oc get network.config.openshift.io cluster -o yaml\\n$ ./openshift-install create manifests\\n$ oc get pods -n openshift-network-operator\\n$ oc logs pod/&lt;network_operator_pod_name&gt; -n openshift-network-operator\\nOpenShift Container Platform 4.11 Support\\n72\\n8\\n. \\nMonitor \\nkubelet.service\\n journald unit logs on control plane nodes, after they have booted. This\\nprovides visibility into control plane node agent activity.\\na\\n. \\nRetrieve the logs using \\noc\\n:\\nb\\n. \\nIf the API is not functional, review the logs using SSH instead. Replace \\n&lt;master-node&gt;.\\n&lt;cluster_name&gt;.&lt;base_domain&gt;\\n with appropriate values:\\nNOTE\\nOpenShift Container Platform 4.11 cluster nodes running Red Hat Enterprise\\nLinux CoreOS (RHCOS) are immutable and rely on Operators to apply\\ncluster changes. Accessing cluster nodes by using SSH is not recommended.\\nBefore attempting to collect diagnostic data over SSH, review whether the\\ndata collected by running \\noc adm must gather\\n and other \\noc\\n commands is\\nsufficient instead. However, if the OpenShift Container Platform API is not\\navailable, or the kubelet is not properly functioning on the target node, \\noc\\noperations will be impacted. In such situations, it is possible to access nodes\\nusing \\nssh core@&lt;node&gt;.&lt;cluster_name&gt;.&lt;base_domain&gt;\\n.\\n9\\n\\nMetadata: {'document_id': 'num-0'}\\n\"</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Result 4\\nContent:  the CRI-O ephemeral storage if you experience the following issues:\\nA node cannot run on any pods and this error appears:\\nYou cannot create a new container on a working node and the “can’t stat lower layer” error\\nappears:\\n$ oc adm node-logs --role=master -u crio\\n$ oc adm node-logs &lt;node_name&gt; -u crio\\n$ ssh core@&lt;node&gt;.&lt;cluster_name&gt;.&lt;base_domain&gt; journalctl -b -f -u crio.service\\nFailed to create pod sandbox: rpc error: code = Unknown desc = failed to mount container\\n \\nXXX: error recreating the missing symlinks: error reading name of symlink for XXX: open\\n \\n/var/lib/containers/storage/overlay/XXX/link: no such file or directory\\nCHAPTER 7. TROUBLESHOOTING\\n89\\nYour node is in the \\nNotReady\\n state after a cluster upgrade or if you attempt to reboot it.\\nThe container runtime implementation (\\ncrio\\n) is not working properly.\\nYou are unable to start a debug shell on the node using \\noc debug node/&lt;node_name&gt;\\nbecause the container runtime instance (\\ncrio\\n) is not working.\\nFollow this process to completely wipe the CRI-O storage and resolve the errors.\\nPrerequisites:\\nYou have access to the cluster as a user with the \\ncluster-admin\\n role.\\nYou have installed the OpenShift CLI (\\noc\\n).\\nProcedure\\n1\\n. \\nUse \\ncordon\\n on the node. This is to avoid any workload getting scheduled if the node gets into\\nthe \\nReady\\n status. You will know that scheduling is disabled when \\nSchedulingDisabled\\n is in your\\nStatus section:\\n2\\n. \\nDrain the node as the cluster-admin user:\\nNOTE\\nThe \\nterminationGracePeriodSeconds\\n attribute of a pod or pod template\\ncontrols the graceful termination period. This attribute defaults at 30 seconds,\\nbut can be customized for each application as necessary. If set to more than 90\\nseconds, the pod might be marked as \\nSIGKILLed\\n and fail to terminate\\nsuccessfully.\\n3\\n. \\nWhen the node returns, connect back to the node via SSH or Console. Then connect to the root\\nuser:\\n4\\n. \\nManually stop the kubelet:\\n5\\n. \\nStop the containers and pods:\\na\\n. \\nUse the following command to stop the pods that are not in the \\nHostNetwork\\n. They must\\nbe removed first because their removal\\nMetadata: {'document_id': 'num-0'}\\n\"</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'Result 5\\nContent: \\n  Normal   Pulling         8s (x3 over 47s)   kubelet            Pulling image \"quay.io/example-\\norg/example-catalog:v1\"\\n  Warning  Failed          8s (x3 over 47s)   kubelet            Failed to pull image\\n \\n\"quay.io/example-org/example-catalog:v1\": rpc error: code = Unknown desc = reading\\n \\nmanifest v1 in quay.io/example-org/example-catalog: unauthorized: access to the requested\\n \\nresource is not authorized\\n  Warning  Failed          8s (x3 over 47s)   kubelet            Error: ErrImagePull\\n$ oc get clusteroperators\\n$ oc get pod -n &lt;operator_namespace&gt;\\nOpenShift Container Platform 4.11 Support\\n104\\n3\\n. \\nOutput a detailed Operator pod summary:\\n4\\n. \\nIf an Operator issue is node-specific, query Operator container status on that node.\\na\\n. \\nStart a debug pod for the node:\\nb\\n. \\nSet \\n/host\\n as the root directory within the debug shell. The debug pod mounts the host’s\\nroot file system in \\n/host\\n within the pod. By changing the root directory to \\n/host\\n, you can run\\nbinaries contained in the host’s executable paths:\\nNOTE\\nOpenShift Container Platform 4.11 cluster nodes running Red Hat Enterprise\\nLinux CoreOS (RHCOS) are immutable and rely on Operators to apply\\ncluster changes. Accessing cluster nodes by using SSH is not recommended.\\nHowever, if the OpenShift Container Platform API is not available, or the\\nkubelet is not properly functioning on the target node, \\noc\\n operations will be\\nimpacted. In such situations, it is possible to access nodes using \\nssh\\n \\ncore@&lt;node&gt;.&lt;cluster_name&gt;.&lt;base_domain&gt;\\n instead.\\nc\\n. \\nList details about the node’s containers, including state and associated pod IDs:\\nd\\n. \\nList information about a specific Operator container on the node. The following example\\nlists information about the \\nnetwork-operator\\n container:\\ne\\n. \\nExit from the debug shell.\\n7.6.5. Gathering Operator logs\\nIf you experience Operator issues, you can gather detailed diagnostic information from Operator pod\\nlogs.\\nPrerequisites\\nYou have access to the cluster as a user with the \\ncluster-admin\\n role.\\nYour API service is still functional.\\nYou have installed the OpenShift CLI (\\noc\\n).\\nYou have the fully qualified domain names of\\nMetadata: {\\'document_id\\': \\'num-0\\'}\\n'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'END of knowledge_search tool results.\\n'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The above results were retrieved to help answer the user\\'s query: \"Kubernetes pod startup failure unknown error missing dependencies configuration errors permission issues\". Use them as supporting information only in answering this query.\\n'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m=\u001b[32m'knowledge_search tool found 5 chunks:\\nBEGIN of knowledge_search tool results.\\n'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m=\u001b[32m'Result 1\\nContent:  period. This attribute defaults at 30 seconds,\\nbut can be customized for each application as necessary. If set to more than 90\\nseconds, the pod might be marked as \\nSIGKILLed\\n and fail to terminate\\nsuccessfully.\\n3\\n. \\nWhen the node returns, connect back to the node via SSH or Console. Then connect to the root\\nuser:\\n4\\n. \\nManually stop the kubelet:\\n5\\n. \\nStop the containers and pods:\\na\\n. \\nUse the following command to stop the pods that are not in the \\nHostNetwork\\n. They must\\nbe removed first because their removal relies on the networking plugin pods, which are in\\nthe \\nHostNetwork\\n.\\ncan\\'t stat lower layer ...  because it does not exist.  Going through storage to recreate the\\n \\nmissing symlinks.\\n$ oc adm cordon \u001b[0m\u001b[32m<\u001b[0m\u001b[32mnode_name\u001b[0m\u001b[32m>\\n$ oc adm drain <node_name> --ignore-daemonsets --delete-emptydir-data\\n$ ssh core@node1.example.com\\n$ sudo -i\\n# systemctl stop kubelet\\nOpenShift Container Platform 4.11 Support\\n90\\nb\\n. \\nStop all other pods:\\n6\\n. \\nManually stop the crio services:\\n7\\n. \\nAfter you run those commands, you can completely wipe the ephemeral storage:\\n8\\n. \\nStart the crio and kubelet service:\\n9\\n. \\nYou will know if the clean up worked if the crio and kubelet services are started, and the node is\\nin the \\nReady\\n status:\\nExample output\\n10\\n. \\nMark the node schedulable. You will know that the scheduling is enabled when \\nSchedulingDisabled\\n is no longer in status:\\nExample output\\n7.4. TROUBLESHOOTING OPERATING SYSTEM ISSUES\\nOpenShift Container Platform runs on RHCOS. You can follow these procedures to troubleshoot\\nproblems related to the operating system.\\n7.4.1. Investigating kernel crashes\\nThe \\nkdump\\n service, included in the \\nkexec-tools\\n package, provides a crash-dumping mechanism. You\\ncan use this service to save the contents of a system’s memory for later analysis.\\nThe \\nx86_64\\n architecture supports kdump in General Availability \u001b[0m\u001b[32m(\u001b[0m\u001b[32mGA\u001b[0m\u001b[32m)\u001b[0m\u001b[32m status, whereas other\\n.. for pod in $\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcrictl pods -q\u001b[0m\u001b[32m)\u001b[0m\u001b[32m; do if \u001b[0m\u001b[32m[\u001b[0m\u001b[32m[\u001b[0m\u001b[32m \"$\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcrictl inspectp $pod | jq -r\\n \\n.status.linux.namespaces.options.network\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\" != \"\\nMetadata: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\'document_id\\': \\'num-0\\'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m\u001b[39m=\u001b[0m\u001b[32m\"Result\u001b[0m\u001b[32m 2\\nContent: . \\nList pods running within the namespace, as well as pod status, error states, restarts, and age:\\n3\\n. \\nDetermine whether the namespace is managed by a deployment configuration:\\nIf the namespace is managed by a deployment configuration, the output includes the\\ndeployment configuration name and a base image reference.\\n4\\n. \\nInspect the base image referenced in the preceding command’s output:\\n5\\n. \\nIf the base image reference is not correct, update the reference in the deployment\\nconfiguration:\\n6\\n. \\nWhen deployment configuration changes on exit, the configuration will automatically redeploy.\\nWatch pod status as the deployment progresses, to determine whether the issue has been\\nresolved:\\n7\\n. \\nReview events within the namespace for diagnostic information relating to pod failures:\\n7.7.3. Inspecting pod and container logs\\nYou can inspect pod and container logs for warnings and error messages related to explicit pod failures.\\nDepending on policy and exit code, pod and container logs remain available after pods have been\\nterminated.\\nPrerequisites\\nYou have access to the cluster as a user with the \\ncluster-admin\\n role.\\nYour API service is still functional.\\nYou have installed the OpenShift CLI \u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\noc\\n\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nProcedure\\n1\\n. \\nQuery logs for a specific pod:\\n2\\n. \\nQuery logs for a specific container within a pod:\\n$ oc get pods\\n$ oc status\\n$ skopeo inspect docker://<image_reference>\\n$ oc edit deployment/my-deployment\\n$ oc get pods -w\\n$ oc get events\\n$ oc logs <pod_name>\\nOpenShift Container Platform 4.11 Support\\n118\\nLogs retrieved using the preceding \\noc logs\\n commands are composed of messages sent to\\nstdout within pods or containers.\\n3\\n. \\nInspect logs contained in \\n/var/log/\\n within a pod.\\na\\n. \\nList log files and subdirectories contained in \\n/var/log\\n within a pod:\\nExample output\\nb\\n. \\nQuery a specific log file contained in \\n/var/log\\n within a pod:\\nExample output\\nc\\n. \\nList log files and subdirectories contained in \\n/var/log\\n within a specific container:\\nd\\n. \\nQuery a specific log file contained in \\n/var/log\\n within a specific container:\\n$ oc logs <pod_name> -c <container_name>\\n$ oc exec <pod_name>  -- ls -alh /var/log\\ntotal 124K\\ndrwxr-xr-x. 1 root root   33 Aug 11 11:23 .\\n\\nMetadata: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m'document_id': 'num-0'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\"\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m\u001b[39m=\u001b[0m\u001b[32m\"Result\u001b[0m\u001b[32m 3\\nContent:  the \\nopenshift-sdn\\n namespace:\\nc\\n. \\nReview logs relating to failed OpenShift Container Platform SDN pods in the \\nopenshift-\\nsdn\\n namespace:\\n7\\n. \\nDetermine cluster network configuration status.\\na\\n. \\nReview whether the cluster’s network configuration exists:\\nb\\n. \\nIf the installer failed to create the network configuration, generate the Kubernetes\\nmanifests again and review message output:\\nc\\n. \\nReview the pod status in the \\nopenshift-network-operator\\n namespace to determine\\nwhether the Cluster Network Operator \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCNO\u001b[0m\u001b[32m)\u001b[0m\u001b[32m is running:\\nd\\n. \\nGather network Operator pod logs from the \\nopenshift-network-operator\\n namespace:\\n8\\n. \\nMonitor \\nkubelet.service\\n journald unit logs on control plane nodes, after they have booted. This\\n$ oc get nodes\\n$ oc describe node <master_node>\\n$ oc get daemonsets -n openshift-sdn\\n$ oc get pods -n openshift-sdn\\n$ oc logs <sdn_pod> -n openshift-sdn\\n$ oc get network.config.openshift.io cluster -o yaml\\n$ ./openshift-install create manifests\\n$ oc get pods -n openshift-network-operator\\n$ oc logs pod/<network_operator_pod_name> -n openshift-network-operator\\nOpenShift Container Platform 4.11 Support\\n72\\n8\\n. \\nMonitor \\nkubelet.service\\n journald unit logs on control plane nodes, after they have booted. This\\nprovides visibility into control plane node agent activity.\\na\\n. \\nRetrieve the logs using \\noc\\n:\\nb\\n. \\nIf the API is not functional, review the logs using SSH instead. Replace \\n<master-node>.\\n<cluster_name>.<base_domain>\\n with appropriate values:\\nNOTE\\nOpenShift Container Platform 4.11 cluster nodes running Red Hat Enterprise\\nLinux CoreOS \u001b[0m\u001b[32m(\u001b[0m\u001b[32mRHCOS\u001b[0m\u001b[32m)\u001b[0m\u001b[32m are immutable and rely on Operators to apply\\ncluster changes. Accessing cluster nodes by using SSH is not recommended.\\nBefore attempting to collect diagnostic data over SSH, review whether the\\ndata collected by running \\noc adm must gather\\n and other \\noc\\n commands is\\nsufficient instead. However, if the OpenShift Container Platform API is not\\navailable, or the kubelet is not properly functioning on the target node, \\noc\\noperations will be impacted. In such situations, it is possible to access nodes\\nusing \\nssh core@<node>.<cluster_name>.<base_domain>\\n.\\n9\\n\\nMetadata: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m'document_id': 'num-0'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\"\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m\u001b[39m=\u001b[0m\u001b[32m\"Result\u001b[0m\u001b[32m 4\\nContent:  the CRI-O ephemeral storage if you experience the following issues:\\nA node cannot run on any pods and this error appears:\\nYou cannot create a new container on a working node and the “can’t stat lower layer” error\\nappears:\\n$ oc adm node-logs --\u001b[0m\u001b[32mrole\u001b[0m\u001b[32m=\u001b[0m\u001b[32mmaster\u001b[0m\u001b[32m -u crio\\n$ oc adm node-logs <node_name> -u crio\\n$ ssh core@<node>.<cluster_name>.<base_domain> journalctl -b -f -u crio.service\\nFailed to create pod sandbox: rpc error: code = Unknown desc = failed to mount container\\n \\nXXX: error recreating the missing symlinks: error reading name of symlink for XXX: open\\n \\n/var/lib/containers/storage/overlay/XXX/link: no such file or directory\\nCHAPTER 7. TROUBLESHOOTING\\n89\\nYour node is in the \\nNotReady\\n state after a cluster upgrade or if you attempt to reboot it.\\nThe container runtime implementation \u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\ncrio\\n\u001b[0m\u001b[32m)\u001b[0m\u001b[32m is not working properly.\\nYou are unable to start a debug shell on the node using \\noc debug node/<node_name>\\nbecause the container runtime instance \u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\ncrio\\n\u001b[0m\u001b[32m)\u001b[0m\u001b[32m is not working.\\nFollow this process to completely wipe the CRI-O storage and resolve the errors.\\nPrerequisites:\\nYou have access to the cluster as a user with the \\ncluster-admin\\n role.\\nYou have installed the OpenShift CLI \u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\noc\\n\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nProcedure\\n1\\n. \\nUse \\ncordon\\n on the node. This is to avoid any workload getting scheduled if the node gets into\\nthe \\nReady\\n status. You will know that scheduling is disabled when \\nSchedulingDisabled\\n is in your\\nStatus section:\\n2\\n. \\nDrain the node as the cluster-admin user:\\nNOTE\\nThe \\nterminationGracePeriodSeconds\\n attribute of a pod or pod template\\ncontrols the graceful termination period. This attribute defaults at 30 seconds,\\nbut can be customized for each application as necessary. If set to more than 90\\nseconds, the pod might be marked as \\nSIGKILLed\\n and fail to terminate\\nsuccessfully.\\n3\\n. \\nWhen the node returns, connect back to the node via SSH or Console. Then connect to the root\\nuser:\\n4\\n. \\nManually stop the kubelet:\\n5\\n. \\nStop the containers and pods:\\na\\n. \\nUse the following command to stop the pods that are not in the \\nHostNetwork\\n. They must\\nbe removed first because their removal\\nMetadata: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m'document_id': 'num-0'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\"\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'Result 5\\nContent: \\n  Normal   Pulling         8s \u001b[0m\u001b[32m(\u001b[0m\u001b[32mx3 over 47s\u001b[0m\u001b[32m)\u001b[0m\u001b[32m   kubelet            Pulling image \"quay.io/example-\\norg/example-catalog:v1\"\\n  Warning  Failed          8s \u001b[0m\u001b[32m(\u001b[0m\u001b[32mx3 over 47s\u001b[0m\u001b[32m)\u001b[0m\u001b[32m   kubelet            Failed to pull image\\n \\n\"quay.io/example-org/example-catalog:v1\": rpc error: code = Unknown desc = reading\\n \\nmanifest v1 in quay.io/example-org/example-catalog: unauthorized: access to the requested\\n \\nresource is not authorized\\n  Warning  Failed          8s \u001b[0m\u001b[32m(\u001b[0m\u001b[32mx3 over 47s\u001b[0m\u001b[32m)\u001b[0m\u001b[32m   kubelet            Error: ErrImagePull\\n$ oc get clusteroperators\\n$ oc get pod -n <operator_namespace>\\nOpenShift Container Platform 4.11 Support\\n104\\n3\\n. \\nOutput a detailed Operator pod summary:\\n4\\n. \\nIf an Operator issue is node-specific, query Operator container status on that node.\\na\\n. \\nStart a debug pod for the node:\\nb\\n. \\nSet \\n/host\\n as the root directory within the debug shell. The debug pod mounts the host’s\\nroot file system in \\n/host\\n within the pod. By changing the root directory to \\n/host\\n, you can run\\nbinaries contained in the host’s executable paths:\\nNOTE\\nOpenShift Container Platform 4.11 cluster nodes running Red Hat Enterprise\\nLinux CoreOS \u001b[0m\u001b[32m(\u001b[0m\u001b[32mRHCOS\u001b[0m\u001b[32m)\u001b[0m\u001b[32m are immutable and rely on Operators to apply\\ncluster changes. Accessing cluster nodes by using SSH is not recommended.\\nHowever, if the OpenShift Container Platform API is not available, or the\\nkubelet is not properly functioning on the target node, \\noc\\n operations will be\\nimpacted. In such situations, it is possible to access nodes using \\nssh\\n \\ncore@<node>.<cluster_name>.<base_domain\u001b[0m\u001b[32m>\u001b[0m\u001b[32m\\n instead.\\nc\\n. \\nList details about the node’s containers, including state and associated pod IDs:\\nd\\n. \\nList information about a specific Operator container on the node. The following example\\nlists information about the \\nnetwork-operator\\n container:\\ne\\n. \\nExit from the debug shell.\\n7.6.5. Gathering Operator logs\\nIf you experience Operator issues, you can gather detailed diagnostic information from Operator pod\\nlogs.\\nPrerequisites\\nYou have access to the cluster as a user with the \\ncluster-admin\\n role.\\nYour API service is still functional.\\nYou have installed the OpenShift CLI \u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\noc\\n\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nYou have the fully qualified domain names of\\nMetadata: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\'document_id\\': \\'num-0\\'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1m(\u001b[0m\u001b[33mtext\u001b[0m=\u001b[32m'END of knowledge_search tool results.\\n'\u001b[0m, \u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m=\u001b[32m'The above results were retrieved to help answer the user\\'s query: \"Kubernetes pod startup failure unknown error missing dependencies configuration errors permission issues\". Use them as supporting information only in answering this query.\\n'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://llamastack:8321/v1/agents/77a2c618-2f48-49b8-b688-a4de3ff6d904/session/9c1cc0d9-8f74-4fff-9ac7-8967e7add797/turn \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- 📍 Step 3: InferenceStep ----------\n",
      "🤖 Model Response:\n",
      "\u001b[35m<think>\n",
      "Okay, the user is facing an issue with a Kubernetes pod named slack-test in the llama-serve namespace. The logs show a startup failure with an unknown error, mentioning possible missing dependencies, configuration errors, or permission issues. I need to find a solution based on the knowledge search results provided.\n",
      "\n",
      "Looking at the knowledge search results, there are several relevant points. Result 1 talks about stopping pods and containers, which might help if there's a conflict. Result 2 suggests checking pod logs and events, which the user already did, but maybe they need to look deeper. Result 4 mentions CRI-O storage issues and steps to drain the node and clear storage, which could resolve permission or dependency problems. Result 5 shows an example of image pull errors due to permissions, so checking image access might be necessary.\n",
      "\n",
      "The user needs a concise summary. The main steps would be: check image permissions and availability, inspect pod events for more details, clear any storage issues using the cordon and drain steps from result 4, and ensure configurations are correct. Also, verifying the deployment configuration and base image as mentioned in result 2 could help. Combining these into 1-2 sentences without being too technical.\n",
      "</think>\n",
      "\n",
      "To resolve the pod startup failure, first verify the container image permissions and availability (Result 5), then inspect pod events and logs for specific errors using `oc get events` and `oc logs` (Result 2). If storage issues persist, clear CRI-O storage by draining the node, stopping containers, and resetting storage as outlined in Result 4.\n",
      "\u001b[0m\n",
      "========== Query processing completed ========== \n",
      "\n",
      "\n",
      "---------- 📍 Step 1: InferenceStep ----------\n",
      "🛠️ Tool call Generated:\n",
      "\u001b[35mTool call: slack_post_message, Arguments: {'channel_id': 'demos', 'text': 'Summary of solution for pod startup failure: Verify container image permissions/availability, inspect pod events/logs with `oc get events` and `oc logs`, and clear CRI-O storage if needed by draining the node, stopping containers, and resetting storage.'}\u001b[0m\n",
      "\n",
      "---------- 📍 Step 2: ToolExecutionStep ----------\n",
      "🔧 Executing tool...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'{\"ok\":false,\"error\":\"invalid_auth\",\"warning\":\"missing_charset\",\"response_metadata\":{\"warnings\":[\"missing_charset\"]}}'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'annotations'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'text'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'text'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"ok\":false,\"error\":\"invalid_auth\",\"warning\":\"missing_charset\",\"response_metadata\":\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"warnings\":\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\"missing_charset\"\u001b[0m\u001b[32m]\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'annotations'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- 📍 Step 3: InferenceStep ----------\n",
      "🤖 Model Response:\n",
      "\u001b[35m<think>\n",
      "Okay, the user tried to send a message to the Slack channel \"demos\" but got an error: \"invalid_auth\" and \"missing_charset\". Let me figure out what's going on here.\n",
      "\n",
      "First, the \"invalid_auth\" error usually means the Slack API token is incorrect or missing. The user might not have the correct credentials set up for the Slack integration. They might need to check if the token is valid and has the necessary permissions.\n",
      "\n",
      "Then there's the \"missing_charset\" warning. That's about the character set in the request. Maybe the message wasn't properly encoded. The user should ensure that the text they're sending is correctly formatted, perhaps specifying the charset in the request headers. But since they're using a tool, maybe the tool's configuration needs adjustment.\n",
      "\n",
      "Wait, the user is using the `slack_post_message` function. The parameters required are `channel_id` and `text`. The channel ID \"demos\" might not be correct. Slack channel IDs usually start with a \"C\" followed by numbers, like \"C1234567890\". The user might have used the channel name instead of the actual ID. They should verify the correct channel ID from Slack's UI or API.\n",
      "\n",
      "So, the main issues are likely an invalid or missing authentication token and using the wrong channel ID format. The user needs to update the Slack tool's configuration with the correct token and use the proper channel ID. Also, ensuring the message is properly encoded might help with the charset warning, but the auth issue is more critical here.\n",
      "\n",
      "I should suggest checking the Slack app's authentication token, verifying the channel ID, and maybe re-installing or re-configuring the Slack integration if necessary. That should resolve the \"invalid_auth\" error and allow the message to be sent successfully.\n",
      "</think>\n",
      "\n",
      "The Slack message failed due to an authentication error (`invalid_auth`) and a missing character set specification. Here's how to resolve it:\n",
      "\n",
      "1. **Verify Slack Authentication**:  \n",
      "   Ensure the Slack API token used by the tool is valid and has the correct permissions (e.g., `chat:write` scope). If the token is expired or incorrect, generate a new one from your Slack app's configuration.\n",
      "\n",
      "2. **Use the Correct Channel ID**:  \n",
      "   Slack channel IDs (e.g., `C1234567890`) are not the same as channel names (e.g., `#demos`). Use `slack_list_channels` to retrieve the correct ID for the `#demos` channel.\n",
      "\n",
      "3. **Retry the Message**:  \n",
      "   Once authentication and channel ID are fixed, retry the message with the corrected parameters.\n",
      "\n",
      "Example corrected tool call:\n",
      "```xml\n",
      "<tool_call>\n",
      "{\"name\": \"slack_post_message\", \"arguments\": {\"channel_id\": \"C1234567890\", \"text\": \"Summary of solution for pod startup failure: Verify container image permissions/availability, inspect pod events/logs with `oc get events` and `oc logs`, and clear CRI-O storage if needed by draining the node, stopping containers, and resetting storage.\"}}\n",
      "</tool_call>\n",
      "```\n",
      "\u001b[0m\n",
      "========== Query processing completed ========== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create simple agent with tools\n",
    "agent = Agent(\n",
    "    client,\n",
    "    model=model_id, # replace this with your choice of model\n",
    "    instructions = model_prompt , # update system prompt based on the model you are using\n",
    "    tools=[dict(\n",
    "            name=\"builtin::rag\",\n",
    "            args={\n",
    "                \"vector_db_ids\": [vector_db_id],  # list of IDs of document collections to consider during retrieval\n",
    "            },\n",
    "        ),\"mcp::openshift\", \"mcp::slack\"],\n",
    "    tool_config={\"tool_choice\":\"auto\"},\n",
    "    sampling_params=sampling_params\n",
    ")\n",
    "\n",
    "user_prompts = [\"View the logs for pod slack-test in the llm OpenShift namespace. Categorize it as normal or error.\",\n",
    "                \"Search for solutions on this error and provide a summary of the steps to take in just 1-2 sentences.\",\n",
    "                \"Send a message with the summarization to the demos channel on Slack with a tool call\"]\n",
    "session_id = agent.create_session(session_name=\"OCP_Slack_demo\")\n",
    "for i, prompt in enumerate(user_prompts):\n",
    "    response = agent.create_turn(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\":\"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        session_id=session_id,\n",
    "        stream=stream,\n",
    "    )\n",
    "    if stream:\n",
    "        for log in EventLogger().log(response):\n",
    "            log.print()\n",
    "    else:\n",
    "        step_printer(response.steps) # print the steps of an agent's response in a formatted way. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a105531",
   "metadata": {},
   "source": [
    "### Output Analysis\n",
    "\n",
    "Lets step through the output to further understands whats happening in this Agentic demo.\n",
    "\n",
    "1. First the LLM sends off a tool call to the `pods_log` tool configured with the OpenShift MCP server, to fetch the logs for the pod specified from the OpenShift cluster.\n",
    "2. The tool successfully retrieves the logs for the pod.\n",
    "3. The LLM recieves the response from the tool call, which are the pod logs, along with the original query and using its own knowledge tries to categorize it as 'Normal or 'Error'.\n",
    "4. Next, the LLM sends a tool call to the RAG tool, to query the vector DB on the documents for the error from the pod logs and look for a solution to resolve the error from the document.\n",
    "5. The LLM recieves the response from the tool call, and summarizes the information it retreived from the document.\n",
    "6. Finally, the LLM sends the summarization as a message on Slack using the `slack_post_message` tool call configured with the Slack MCP server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f6c84d",
   "metadata": {},
   "source": [
    "## Defining our Agent - ReAct\n",
    "\n",
    "Now that we've shown that we can successfully accomplish this multi-step multi-tool task using prompt chaining, let's see if we can give our agent a bit more autonomy to perform the same task but with a single prompt instead of a chian. To do this, we will instantiate a ReAct agent (which is included in the llama stack python client by default). The ReAct agent is a variant of the simple agent but with the ability to loop through \"Reason then Act\" iterations, thinking through the problem and then using tools until it determines that it's task has been completed successfully.\n",
    "\n",
    "Unlike prompt chaining which follows fixed steps, ReAct dynamically breaks down tasks and adapts its approach based on the results of each step. This makes it more flexible and capable of handling complex, real-world queries effectively.\n",
    "\n",
    "Below you will see the slight differences in the agent definition and the prompt used to accomplish our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a606a5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://llamastack:8321/v1/tools?toolgroup_id=mcp%3A%3Aslack \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://llamastack:8321/v1/tools?toolgroup_id=mcp%3A%3Aopenshift \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://llamastack:8321/v1/tools?toolgroup_id=builtin%3A%3Arag \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://llamastack:8321/v1/agents \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://llamastack:8321/v1/tools?toolgroup_id=mcp%3A%3Aslack \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://llamastack:8321/v1/tools?toolgroup_id=mcp%3A%3Aopenshift \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://llamastack:8321/v1/tools?toolgroup_id=builtin%3A%3Arag \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://llamastack:8321/v1/agents/24730326-f947-405b-9b48-1ad698ac32dc/session \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://llamastack:8321/v1/agents/24730326-f947-405b-9b48-1ad698ac32dc/session/f08fafde-af4a-4892-8ac9-3cd54db70b17/turn \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "\u001b[34mProcessing user query: View the logs for pod slack-test in the llama-serve OpenShift namespace. Categorize it as normal or error, \n",
      "                search for solutions on this error and provide a summary of the steps to take in just 1-2 sentences.\n",
      "                Send a message with the summarization to the demos channel on Slack. Let me know when you've sent the message.\n",
      "                \u001b[0m\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://llamastack:8321/v1/tool-runtime/invoke \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://llamastack:8321/v1/agents/24730326-f947-405b-9b48-1ad698ac32dc/session/f08fafde-af4a-4892-8ac9-3cd54db70b17/turn/99d0d17b-39de-4c5d-bcfa-bb92e1da1fda/resume \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://llamastack:8321/v1/tool-runtime/invoke \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://llamastack:8321/v1/agents/24730326-f947-405b-9b48-1ad698ac32dc/session/f08fafde-af4a-4892-8ac9-3cd54db70b17/turn/99d0d17b-39de-4c5d-bcfa-bb92e1da1fda/resume \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://llamastack:8321/v1/tool-runtime/invoke \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://llamastack:8321/v1/agents/24730326-f947-405b-9b48-1ad698ac32dc/session/f08fafde-af4a-4892-8ac9-3cd54db70b17/turn/99d0d17b-39de-4c5d-bcfa-bb92e1da1fda/resume \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- 📍 Step 1: InferenceStep ----------\n",
      "🤖 Model Response:\n",
      "\u001b[35m{\"thought\": \"I will proceed step by step: first, I will get the logs for the pod 'slack-test' in the 'llama-serve' namespace. Then, I will analyze the logs to categorize them as normal or error. After that, I will search for solutions related to any errors found. Finally, I will summarize the steps to take and send a message to the 'demos' channel on Slack.\", \"action\": {\"tool_name\": \"pods_log\", \"tool_params\": [{\"name\": \"name\", \"value\": \"slack-test\"}, {\"name\": \"namespace\", \"value\": \"llama-serve\"}]}, \"answer\": null}\n",
      "\u001b[0m\n",
      "\n",
      "---------- 📍 Step 2: ToolExecutionStep ----------\n",
      "🔧 Executing tool...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Starting container...\\nFailure: Unknown Error\\nError details: Container failed due to an unexpected issue during startup.\\nPotential cause: Missing dependencies, configuration errors, or permission issues.\\n'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'annotations'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'text'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'text'\u001b[0m: \u001b[32m'Starting container...\\nFailure: Unknown Error\\nError details: Container failed due to an unexpected issue during startup.\\nPotential cause: Missing dependencies, configuration errors, or permission issues.\\n'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'annotations'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- 📍 Step 3: InferenceStep ----------\n",
      "🤖 Model Response:\n",
      "\u001b[35m{\"thought\": \"The logs indicate an error with the container startup. I will categorize this as an error and search for solutions related to the mentioned potential causes: missing dependencies, configuration errors, or permission issues.\", \"action\": {\"tool_name\": \"knowledge_search\", \"tool_params\": [{\"name\": \"query\", \"value\": \"Kubernetes container startup error missing dependencies configuration errors permission issues\"}]}, \"answer\": null}\n",
      "\u001b[0m\n",
      "\n",
      "---------- 📍 Step 4: ToolExecutionStep ----------\n",
      "🔧 Executing tool...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'knowledge_search tool found 5 chunks:\\nBEGIN of knowledge_search tool results.\\n'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Result 1\\nContent:  period. This attribute defaults at 30 seconds,\\nbut can be customized for each application as necessary. If set to more than 90\\nseconds, the pod might be marked as \\nSIGKILLed\\n and fail to terminate\\nsuccessfully.\\n3\\n. \\nWhen the node returns, connect back to the node via SSH or Console. Then connect to the root\\nuser:\\n4\\n. \\nManually stop the kubelet:\\n5\\n. \\nStop the containers and pods:\\na\\n. \\nUse the following command to stop the pods that are not in the \\nHostNetwork\\n. They must\\nbe removed first because their removal relies on the networking plugin pods, which are in\\nthe \\nHostNetwork\\n.\\ncan\\'t stat lower layer ...  because it does not exist.  Going through storage to recreate the\\n \\nmissing symlinks.\\n$ oc adm cordon &lt;node_name&gt;\\n$ oc adm drain &lt;node_name&gt; --ignore-daemonsets --delete-emptydir-data\\n$ ssh core@node1.example.com\\n$ sudo -i\\n# systemctl stop kubelet\\nOpenShift Container Platform 4.11 Support\\n90\\nb\\n. \\nStop all other pods:\\n6\\n. \\nManually stop the crio services:\\n7\\n. \\nAfter you run those commands, you can completely wipe the ephemeral storage:\\n8\\n. \\nStart the crio and kubelet service:\\n9\\n. \\nYou will know if the clean up worked if the crio and kubelet services are started, and the node is\\nin the \\nReady\\n status:\\nExample output\\n10\\n. \\nMark the node schedulable. You will know that the scheduling is enabled when \\nSchedulingDisabled\\n is no longer in status:\\nExample output\\n7.4. TROUBLESHOOTING OPERATING SYSTEM ISSUES\\nOpenShift Container Platform runs on RHCOS. You can follow these procedures to troubleshoot\\nproblems related to the operating system.\\n7.4.1. Investigating kernel crashes\\nThe \\nkdump\\n service, included in the \\nkexec-tools\\n package, provides a crash-dumping mechanism. You\\ncan use this service to save the contents of a system’s memory for later analysis.\\nThe \\nx86_64\\n architecture supports kdump in General Availability (GA) status, whereas other\\n.. for pod in $(crictl pods -q); do if [[ \"$(crictl inspectp $pod | jq -r\\n \\n.status.linux.namespaces.options.network)\" != \"\\nMetadata: {\\'document_id\\': \\'num-0\\'}\\n'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Result 2\\nContent:  the CRI-O ephemeral storage if you experience the following issues:\\nA node cannot run on any pods and this error appears:\\nYou cannot create a new container on a working node and the “can’t stat lower layer” error\\nappears:\\n$ oc adm node-logs --role=master -u crio\\n$ oc adm node-logs &lt;node_name&gt; -u crio\\n$ ssh core@&lt;node&gt;.&lt;cluster_name&gt;.&lt;base_domain&gt; journalctl -b -f -u crio.service\\nFailed to create pod sandbox: rpc error: code = Unknown desc = failed to mount container\\n \\nXXX: error recreating the missing symlinks: error reading name of symlink for XXX: open\\n \\n/var/lib/containers/storage/overlay/XXX/link: no such file or directory\\nCHAPTER 7. TROUBLESHOOTING\\n89\\nYour node is in the \\nNotReady\\n state after a cluster upgrade or if you attempt to reboot it.\\nThe container runtime implementation (\\ncrio\\n) is not working properly.\\nYou are unable to start a debug shell on the node using \\noc debug node/&lt;node_name&gt;\\nbecause the container runtime instance (\\ncrio\\n) is not working.\\nFollow this process to completely wipe the CRI-O storage and resolve the errors.\\nPrerequisites:\\nYou have access to the cluster as a user with the \\ncluster-admin\\n role.\\nYou have installed the OpenShift CLI (\\noc\\n).\\nProcedure\\n1\\n. \\nUse \\ncordon\\n on the node. This is to avoid any workload getting scheduled if the node gets into\\nthe \\nReady\\n status. You will know that scheduling is disabled when \\nSchedulingDisabled\\n is in your\\nStatus section:\\n2\\n. \\nDrain the node as the cluster-admin user:\\nNOTE\\nThe \\nterminationGracePeriodSeconds\\n attribute of a pod or pod template\\ncontrols the graceful termination period. This attribute defaults at 30 seconds,\\nbut can be customized for each application as necessary. If set to more than 90\\nseconds, the pod might be marked as \\nSIGKILLed\\n and fail to terminate\\nsuccessfully.\\n3\\n. \\nWhen the node returns, connect back to the node via SSH or Console. Then connect to the root\\nuser:\\n4\\n. \\nManually stop the kubelet:\\n5\\n. \\nStop the containers and pods:\\na\\n. \\nUse the following command to stop the pods that are not in the \\nHostNetwork\\n. They must\\nbe removed first because their removal\\nMetadata: {'document_id': 'num-0'}\\n\"</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'Result 3\\nContent: \\n  Normal   Pulling         8s (x3 over 47s)   kubelet            Pulling image \"quay.io/example-\\norg/example-catalog:v1\"\\n  Warning  Failed          8s (x3 over 47s)   kubelet            Failed to pull image\\n \\n\"quay.io/example-org/example-catalog:v1\": rpc error: code = Unknown desc = reading\\n \\nmanifest v1 in quay.io/example-org/example-catalog: unauthorized: access to the requested\\n \\nresource is not authorized\\n  Warning  Failed          8s (x3 over 47s)   kubelet            Error: ErrImagePull\\n$ oc get clusteroperators\\n$ oc get pod -n &lt;operator_namespace&gt;\\nOpenShift Container Platform 4.11 Support\\n104\\n3\\n. \\nOutput a detailed Operator pod summary:\\n4\\n. \\nIf an Operator issue is node-specific, query Operator container status on that node.\\na\\n. \\nStart a debug pod for the node:\\nb\\n. \\nSet \\n/host\\n as the root directory within the debug shell. The debug pod mounts the host’s\\nroot file system in \\n/host\\n within the pod. By changing the root directory to \\n/host\\n, you can run\\nbinaries contained in the host’s executable paths:\\nNOTE\\nOpenShift Container Platform 4.11 cluster nodes running Red Hat Enterprise\\nLinux CoreOS (RHCOS) are immutable and rely on Operators to apply\\ncluster changes. Accessing cluster nodes by using SSH is not recommended.\\nHowever, if the OpenShift Container Platform API is not available, or the\\nkubelet is not properly functioning on the target node, \\noc\\n operations will be\\nimpacted. In such situations, it is possible to access nodes using \\nssh\\n \\ncore@&lt;node&gt;.&lt;cluster_name&gt;.&lt;base_domain&gt;\\n instead.\\nc\\n. \\nList details about the node’s containers, including state and associated pod IDs:\\nd\\n. \\nList information about a specific Operator container on the node. The following example\\nlists information about the \\nnetwork-operator\\n container:\\ne\\n. \\nExit from the debug shell.\\n7.6.5. Gathering Operator logs\\nIf you experience Operator issues, you can gather detailed diagnostic information from Operator pod\\nlogs.\\nPrerequisites\\nYou have access to the cluster as a user with the \\ncluster-admin\\n role.\\nYour API service is still functional.\\nYou have installed the OpenShift CLI (\\noc\\n).\\nYou have the fully qualified domain names of\\nMetadata: {\\'document_id\\': \\'num-0\\'}\\n'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Result 4\\nContent: .\\nPrerequisites\\nYou have access to the cluster as a user with the \\ncluster-admin\\n role.\\n$ ssh core@&lt;bootstrap_fqdn&gt; journalctl -b -f -u bootkube.service\\n$ ssh core@&lt;bootstrap_fqdn&gt; 'for pod in $(sudo podman ps -a -q); do sudo podman\\n \\nlogs $pod; done'\\nOpenShift Container Platform 4.11 Support\\n70\\n1\\nYou have installed the OpenShift CLI (\\noc\\n).\\nYou have SSH access to your hosts.\\nYou have the fully qualified domain names of the bootstrap and control plane nodes.\\nIf you are hosting Ignition configuration files by using an HTTP server, you must have the HTTP\\nserver’s fully qualified domain name and the port number. You must also have SSH access to\\nthe HTTP host.\\nNOTE\\nThe initial \\nkubeadmin\\n password can be found in \\n&lt;install_directory&gt;/auth/kubeadmin-password\\n on the installation host.\\nProcedure\\n1\\n. \\nIf you have access to the console for the control plane node, monitor the console until the node\\nreaches the login prompt. During the installation, Ignition log messages are output to the\\nconsole.\\n2\\n. \\nVerify Ignition file configuration.\\nIf you are hosting Ignition configuration files by using an HTTP server.\\na\\n. \\nVerify the control plane node Ignition file URL. Replace \\n&lt;http_server_fqdn&gt;\\n with HTTP\\nserver’s fully qualified domain name:\\nThe \\n-I\\n option returns the header only. If the Ignition file is available on the specified\\nURL, the command returns \\n200 OK\\n status. If it is not available, the command\\nreturns \\n404 file not found\\n.\\nb\\n. \\nTo verify that the Ignition file was received by the control plane node query the HTTP\\nserver logs on the serving host. For example, if you are using an Apache web server to\\nserve Ignition files:\\nIf the master Ignition file is received, the associated \\nHTTP GET\\n log message will include\\na \\n200 OK\\n success status, indicating that the request succeeded.\\nc\\n. \\nIf the Ignition file was not received, check that it exists on the serving host directly.\\nEnsure that the appropriate file and web server permissions are in place.\\nIf you are using a cloud provider mechanism to inject Ignition configuration files into hosts as\\npart of their initial deployment.\\na\\n. \\nReview the console for the control plane node to determine if the mechanism is\\ninject\\nMetadata: {'document_id': 'num-0'}\\n\"</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Result 5\\nContent: .\\nErrInvalidImage\\nName\\nThe specified image name was invalid.\\nErrImageInspec\\nt\\nImage inspection did not succeed.\\nErrImageNeverP\\null\\nPullPolicy\\n is set to \\nNeverPullImage\\n and the target image is not present locally on\\nthe host.\\nErrRegistryUna\\nvailable\\nWhen attempting to retrieve an image from a registry, an HTTP error was encountered.\\nErrContainerNot\\nFound\\nThe specified container is either not present or not managed by the kubelet, within the\\ndeclared pod.\\nOpenShift Container Platform 4.11 Support\\n116\\nErrRunInitConta\\niner\\nContainer initialization failed.\\nErrRunContaine\\nr\\nNone of the pod’s containers started successfully.\\nErrKillContainer\\nNone of the pod’s containers were killed successfully.\\nErrCrashLoopB\\nackOff\\nA container has terminated. The kubelet will not attempt to restart it.\\nErrVerifyNonRo\\not\\nA container or image attempted to run with root privileges.\\nErrCreatePodSa\\nndbox\\nPod sandbox creation did not succeed.\\nErrConfigPodSa\\nndbox\\nPod sandbox configuration was not obtained.\\nErrKillPodSand\\nbox\\nA pod sandbox did not stop successfully.\\nErrSetupNetwor\\nk\\nNetwork initialization failed.\\nErrTeardownNet\\nwork\\nNetwork termination failed.\\nPod error state\\nDescription\\n7.7.2. Reviewing pod status\\nYou can query pod status and error states. You can also query a pod’s associated deployment\\nconfiguration and review base image availability.\\nPrerequisites\\nYou have access to the cluster as a user with the \\ncluster-admin\\n role.\\nYou have installed the OpenShift CLI (\\noc\\n).\\nskopeo\\n is installed.\\nProcedure\\n1\\n. \\nSwitch into a project:\\n$ oc project &lt;project_name&gt;\\nCHAPTER 7. TROUBLESHOOTING\\n117\\n2\\n. \\nList pods running within the namespace, as well as pod status, error states, restarts, and age:\\n3\\n. \\nDetermine whether the namespace is managed by a deployment configuration:\\nIf the namespace is managed by a deployment configuration, the output includes the\\ndeployment configuration name and a base image reference.\\n4\\n. \\nInspect the base image referenced in the preceding command’s output:\\n5\\n. \\nIf the base image reference is not correct, update the reference in the deployment\\nconfiguration:\\n6\\n. \\nWhen deployment configuration changes on exit, the configuration will automatically redeploy.\\nWatch pod status as the deployment progresses,\\nMetadata: {'document_id': 'num-0'}\\n\"</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'END of knowledge_search tool results.\\n'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The above results were retrieved to help answer the user\\'s query: \"Kubernetes container startup error missing dependencies configuration errors permission issues\". Use them as supporting information only in answering this query.\\n'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m=\u001b[32m'knowledge_search tool found 5 chunks:\\nBEGIN of knowledge_search tool results.\\n'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m=\u001b[32m'Result 1\\nContent:  period. This attribute defaults at 30 seconds,\\nbut can be customized for each application as necessary. If set to more than 90\\nseconds, the pod might be marked as \\nSIGKILLed\\n and fail to terminate\\nsuccessfully.\\n3\\n. \\nWhen the node returns, connect back to the node via SSH or Console. Then connect to the root\\nuser:\\n4\\n. \\nManually stop the kubelet:\\n5\\n. \\nStop the containers and pods:\\na\\n. \\nUse the following command to stop the pods that are not in the \\nHostNetwork\\n. They must\\nbe removed first because their removal relies on the networking plugin pods, which are in\\nthe \\nHostNetwork\\n.\\ncan\\'t stat lower layer ...  because it does not exist.  Going through storage to recreate the\\n \\nmissing symlinks.\\n$ oc adm cordon \u001b[0m\u001b[32m<\u001b[0m\u001b[32mnode_name\u001b[0m\u001b[32m>\\n$ oc adm drain <node_name> --ignore-daemonsets --delete-emptydir-data\\n$ ssh core@node1.example.com\\n$ sudo -i\\n# systemctl stop kubelet\\nOpenShift Container Platform 4.11 Support\\n90\\nb\\n. \\nStop all other pods:\\n6\\n. \\nManually stop the crio services:\\n7\\n. \\nAfter you run those commands, you can completely wipe the ephemeral storage:\\n8\\n. \\nStart the crio and kubelet service:\\n9\\n. \\nYou will know if the clean up worked if the crio and kubelet services are started, and the node is\\nin the \\nReady\\n status:\\nExample output\\n10\\n. \\nMark the node schedulable. You will know that the scheduling is enabled when \\nSchedulingDisabled\\n is no longer in status:\\nExample output\\n7.4. TROUBLESHOOTING OPERATING SYSTEM ISSUES\\nOpenShift Container Platform runs on RHCOS. You can follow these procedures to troubleshoot\\nproblems related to the operating system.\\n7.4.1. Investigating kernel crashes\\nThe \\nkdump\\n service, included in the \\nkexec-tools\\n package, provides a crash-dumping mechanism. You\\ncan use this service to save the contents of a system’s memory for later analysis.\\nThe \\nx86_64\\n architecture supports kdump in General Availability \u001b[0m\u001b[32m(\u001b[0m\u001b[32mGA\u001b[0m\u001b[32m)\u001b[0m\u001b[32m status, whereas other\\n.. for pod in $\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcrictl pods -q\u001b[0m\u001b[32m)\u001b[0m\u001b[32m; do if \u001b[0m\u001b[32m[\u001b[0m\u001b[32m[\u001b[0m\u001b[32m \"$\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcrictl inspectp $pod | jq -r\\n \\n.status.linux.namespaces.options.network\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\" != \"\\nMetadata: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\'document_id\\': \\'num-0\\'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m\u001b[39m=\u001b[0m\u001b[32m\"Result\u001b[0m\u001b[32m 2\\nContent:  the CRI-O ephemeral storage if you experience the following issues:\\nA node cannot run on any pods and this error appears:\\nYou cannot create a new container on a working node and the “can’t stat lower layer” error\\nappears:\\n$ oc adm node-logs --\u001b[0m\u001b[32mrole\u001b[0m\u001b[32m=\u001b[0m\u001b[32mmaster\u001b[0m\u001b[32m -u crio\\n$ oc adm node-logs <node_name> -u crio\\n$ ssh core@<node>.<cluster_name>.<base_domain> journalctl -b -f -u crio.service\\nFailed to create pod sandbox: rpc error: code = Unknown desc = failed to mount container\\n \\nXXX: error recreating the missing symlinks: error reading name of symlink for XXX: open\\n \\n/var/lib/containers/storage/overlay/XXX/link: no such file or directory\\nCHAPTER 7. TROUBLESHOOTING\\n89\\nYour node is in the \\nNotReady\\n state after a cluster upgrade or if you attempt to reboot it.\\nThe container runtime implementation \u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\ncrio\\n\u001b[0m\u001b[32m)\u001b[0m\u001b[32m is not working properly.\\nYou are unable to start a debug shell on the node using \\noc debug node/<node_name>\\nbecause the container runtime instance \u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\ncrio\\n\u001b[0m\u001b[32m)\u001b[0m\u001b[32m is not working.\\nFollow this process to completely wipe the CRI-O storage and resolve the errors.\\nPrerequisites:\\nYou have access to the cluster as a user with the \\ncluster-admin\\n role.\\nYou have installed the OpenShift CLI \u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\noc\\n\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nProcedure\\n1\\n. \\nUse \\ncordon\\n on the node. This is to avoid any workload getting scheduled if the node gets into\\nthe \\nReady\\n status. You will know that scheduling is disabled when \\nSchedulingDisabled\\n is in your\\nStatus section:\\n2\\n. \\nDrain the node as the cluster-admin user:\\nNOTE\\nThe \\nterminationGracePeriodSeconds\\n attribute of a pod or pod template\\ncontrols the graceful termination period. This attribute defaults at 30 seconds,\\nbut can be customized for each application as necessary. If set to more than 90\\nseconds, the pod might be marked as \\nSIGKILLed\\n and fail to terminate\\nsuccessfully.\\n3\\n. \\nWhen the node returns, connect back to the node via SSH or Console. Then connect to the root\\nuser:\\n4\\n. \\nManually stop the kubelet:\\n5\\n. \\nStop the containers and pods:\\na\\n. \\nUse the following command to stop the pods that are not in the \\nHostNetwork\\n. They must\\nbe removed first because their removal\\nMetadata: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m'document_id': 'num-0'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\"\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'Result 3\\nContent: \\n  Normal   Pulling         8s \u001b[0m\u001b[32m(\u001b[0m\u001b[32mx3 over 47s\u001b[0m\u001b[32m)\u001b[0m\u001b[32m   kubelet            Pulling image \"quay.io/example-\\norg/example-catalog:v1\"\\n  Warning  Failed          8s \u001b[0m\u001b[32m(\u001b[0m\u001b[32mx3 over 47s\u001b[0m\u001b[32m)\u001b[0m\u001b[32m   kubelet            Failed to pull image\\n \\n\"quay.io/example-org/example-catalog:v1\": rpc error: code = Unknown desc = reading\\n \\nmanifest v1 in quay.io/example-org/example-catalog: unauthorized: access to the requested\\n \\nresource is not authorized\\n  Warning  Failed          8s \u001b[0m\u001b[32m(\u001b[0m\u001b[32mx3 over 47s\u001b[0m\u001b[32m)\u001b[0m\u001b[32m   kubelet            Error: ErrImagePull\\n$ oc get clusteroperators\\n$ oc get pod -n <operator_namespace>\\nOpenShift Container Platform 4.11 Support\\n104\\n3\\n. \\nOutput a detailed Operator pod summary:\\n4\\n. \\nIf an Operator issue is node-specific, query Operator container status on that node.\\na\\n. \\nStart a debug pod for the node:\\nb\\n. \\nSet \\n/host\\n as the root directory within the debug shell. The debug pod mounts the host’s\\nroot file system in \\n/host\\n within the pod. By changing the root directory to \\n/host\\n, you can run\\nbinaries contained in the host’s executable paths:\\nNOTE\\nOpenShift Container Platform 4.11 cluster nodes running Red Hat Enterprise\\nLinux CoreOS \u001b[0m\u001b[32m(\u001b[0m\u001b[32mRHCOS\u001b[0m\u001b[32m)\u001b[0m\u001b[32m are immutable and rely on Operators to apply\\ncluster changes. Accessing cluster nodes by using SSH is not recommended.\\nHowever, if the OpenShift Container Platform API is not available, or the\\nkubelet is not properly functioning on the target node, \\noc\\n operations will be\\nimpacted. In such situations, it is possible to access nodes using \\nssh\\n \\ncore@<node>.<cluster_name>.<base_domain>\\n instead.\\nc\\n. \\nList details about the node’s containers, including state and associated pod IDs:\\nd\\n. \\nList information about a specific Operator container on the node. The following example\\nlists information about the \\nnetwork-operator\\n container:\\ne\\n. \\nExit from the debug shell.\\n7.6.5. Gathering Operator logs\\nIf you experience Operator issues, you can gather detailed diagnostic information from Operator pod\\nlogs.\\nPrerequisites\\nYou have access to the cluster as a user with the \\ncluster-admin\\n role.\\nYour API service is still functional.\\nYou have installed the OpenShift CLI \u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\noc\\n\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nYou have the fully qualified domain names of\\nMetadata: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\'document_id\\': \\'num-0\\'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m\u001b[39m=\u001b[0m\u001b[32m\"Result\u001b[0m\u001b[32m 4\\nContent: .\\nPrerequisites\\nYou have access to the cluster as a user with the \\ncluster-admin\\n role.\\n$ ssh core@<bootstrap_fqdn> journalctl -b -f -u bootkube.service\\n$ ssh core@<bootstrap_fqdn> 'for pod in $\u001b[0m\u001b[32m(\u001b[0m\u001b[32msudo podman ps -a -q\u001b[0m\u001b[32m)\u001b[0m\u001b[32m; do sudo podman\\n \\nlogs $pod; done'\\nOpenShift Container Platform 4.11 Support\\n70\\n1\\nYou have installed the OpenShift CLI \u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\noc\\n\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nYou have SSH access to your hosts.\\nYou have the fully qualified domain names of the bootstrap and control plane nodes.\\nIf you are hosting Ignition configuration files by using an HTTP server, you must have the HTTP\\nserver’s fully qualified domain name and the port number. You must also have SSH access to\\nthe HTTP host.\\nNOTE\\nThe initial \\nkubeadmin\\n password can be found in \\n<install_directory>/auth/kubeadmin-password\\n on the installation host.\\nProcedure\\n1\\n. \\nIf you have access to the console for the control plane node, monitor the console until the node\\nreaches the login prompt. During the installation, Ignition log messages are output to the\\nconsole.\\n2\\n. \\nVerify Ignition file configuration.\\nIf you are hosting Ignition configuration files by using an HTTP server.\\na\\n. \\nVerify the control plane node Ignition file URL. Replace \\n<http_server_fqdn>\\n with HTTP\\nserver’s fully qualified domain name:\\nThe \\n-I\\n option returns the header only. If the Ignition file is available on the specified\\nURL, the command returns \\n200 OK\\n status. If it is not available, the command\\nreturns \\n404 file not found\\n.\\nb\\n. \\nTo verify that the Ignition file was received by the control plane node query the HTTP\\nserver logs on the serving host. For example, if you are using an Apache web server to\\nserve Ignition files:\\nIf the master Ignition file is received, the associated \\nHTTP GET\\n log message will include\\na \\n200 OK\\n success status, indicating that the request succeeded.\\nc\\n. \\nIf the Ignition file was not received, check that it exists on the serving host directly.\\nEnsure that the appropriate file and web server permissions are in place.\\nIf you are using a cloud provider mechanism to inject Ignition configuration files into hosts as\\npart of their initial deployment.\\na\\n. \\nReview the console for the control plane node to determine if the mechanism is\\ninject\\nMetadata: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m'document_id': 'num-0'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\"\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m\u001b[39m=\u001b[0m\u001b[32m\"Result\u001b[0m\u001b[32m 5\\nContent: .\\nErrInvalidImage\\nName\\nThe specified image name was invalid.\\nErrImageInspec\\nt\\nImage inspection did not succeed.\\nErrImageNeverP\\null\\nPullPolicy\\n is set to \\nNeverPullImage\\n and the target image is not present locally on\\nthe host.\\nErrRegistryUna\\nvailable\\nWhen attempting to retrieve an image from a registry, an HTTP error was encountered.\\nErrContainerNot\\nFound\\nThe specified container is either not present or not managed by the kubelet, within the\\ndeclared pod.\\nOpenShift Container Platform 4.11 Support\\n116\\nErrRunInitConta\\niner\\nContainer initialization failed.\\nErrRunContaine\\nr\\nNone of the pod’s containers started successfully.\\nErrKillContainer\\nNone of the pod’s containers were killed successfully.\\nErrCrashLoopB\\nackOff\\nA container has terminated. The kubelet will not attempt to restart it.\\nErrVerifyNonRo\\not\\nA container or image attempted to run with root privileges.\\nErrCreatePodSa\\nndbox\\nPod sandbox creation did not succeed.\\nErrConfigPodSa\\nndbox\\nPod sandbox configuration was not obtained.\\nErrKillPodSand\\nbox\\nA pod sandbox did not stop successfully.\\nErrSetupNetwor\\nk\\nNetwork initialization failed.\\nErrTeardownNet\\nwork\\nNetwork termination failed.\\nPod error state\\nDescription\\n7.7.2. Reviewing pod status\\nYou can query pod status and error states. You can also query a pod’s associated deployment\\nconfiguration and review base image availability.\\nPrerequisites\\nYou have access to the cluster as a user with the \\ncluster-admin\\n role.\\nYou have installed the OpenShift CLI \u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\noc\\n\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nskopeo\\n is installed.\\nProcedure\\n1\\n. \\nSwitch into a project:\\n$ oc project <project_name\u001b[0m\u001b[32m>\u001b[0m\u001b[32m\\nCHAPTER 7. TROUBLESHOOTING\\n117\\n2\\n. \\nList pods running within the namespace, as well as pod status, error states, restarts, and age:\\n3\\n. \\nDetermine whether the namespace is managed by a deployment configuration:\\nIf the namespace is managed by a deployment configuration, the output includes the\\ndeployment configuration name and a base image reference.\\n4\\n. \\nInspect the base image referenced in the preceding command’s output:\\n5\\n. \\nIf the base image reference is not correct, update the reference in the deployment\\nconfiguration:\\n6\\n. \\nWhen deployment configuration changes on exit, the configuration will automatically redeploy.\\nWatch pod status as the deployment progresses,\\nMetadata: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m'document_id': 'num-0'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\"\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1m(\u001b[0m\u001b[33mtext\u001b[0m=\u001b[32m'END of knowledge_search tool results.\\n'\u001b[0m, \u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m=\u001b[32m'The above results were retrieved to help answer the user\\'s query: \"Kubernetes container startup error missing dependencies configuration errors permission issues\". Use them as supporting information only in answering this query.\\n'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- 📍 Step 5: InferenceStep ----------\n",
      "🤖 Model Response:\n",
      "\u001b[35m{\"thought\": \"The knowledge search results suggest common issues like missing dependencies, configuration errors, and permission problems. The logs indicate a failure during container startup, possibly due to these causes. I will summarize the steps to address these issues and prepare a message for the 'demos' channel on Slack.\", \"action\": {\"tool_name\": \"slack_post_message\", \"tool_params\": [{\"name\": \"channel_id\", \"value\": \"demos\"}, {\"name\": \"text\", \"value\": \"The 'slack-test' pod in the 'llama-serve' namespace encountered an error during startup. Potential causes include missing dependencies, configuration errors, or permission issues. Steps to resolve: 1) Check and install any missing dependencies. 2) Review and correct the pod's configuration. 3) Ensure proper permissions are set for the container. 4) Verify the container image and its accessibility.\"}]}, \"answer\": null}\n",
      "\u001b[0m\n",
      "\n",
      "---------- 📍 Step 6: ToolExecutionStep ----------\n",
      "🔧 Executing tool...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'{\"ok\":false,\"error\":\"invalid_auth\",\"warning\":\"missing_charset\",\"response_metadata\":{\"warnings\":[\"missing_charset\"]}}'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'annotations'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'text'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'text'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"ok\":false,\"error\":\"invalid_auth\",\"warning\":\"missing_charset\",\"response_metadata\":\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"warnings\":\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\"missing_charset\"\u001b[0m\u001b[32m]\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'annotations'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- 📍 Step 7: InferenceStep ----------\n",
      "🤖 Model Response:\n",
      "\u001b[35m{\"thought\": \"The Slack message posting failed due to an authentication error. I need to ensure that the correct authentication token is being used for the Slack API. However, since I don't have the capability to manage authentication tokens directly, I should inform the user of the issue and suggest checking the authentication credentials or permissions for the Slack integration.\", \"action\": null, \"answer\": \"Failed to send the message to the 'demos' channel on Slack due to an authentication error. Please check the authentication credentials or permissions for the Slack integration and try again.\"}\n",
      "\u001b[0m\n",
      "========== Query processing completed ========== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "builtin_rag = dict(\n",
    "            name=\"builtin::rag\",\n",
    "            args={\n",
    "                \"vector_db_ids\": [vector_db_id],  # list of IDs of document collections to consider during retrieval\n",
    "            },\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "agent = ReActAgent(\n",
    "            client=client,\n",
    "            model=model_id,\n",
    "            tools=[\"mcp::slack\",\"mcp::openshift\", builtin_rag],\n",
    "            response_format={\n",
    "                \"type\": \"json_schema\",\n",
    "                \"json_schema\": ReActOutput.model_json_schema(),\n",
    "            },\n",
    "            sampling_params={\"max_tokens\":512},\n",
    "        )\n",
    "\n",
    "user_prompts = [\"\"\"View the logs for pod slack-test in the llm OpenShift namespace. Categorize it as normal or error, \n",
    "                search for solutions on this error and provide a summary of the steps to take in just 1-2 sentences.\n",
    "                Send a message with the summarization to the demos channel on Slack. Let me know when you've sent the message.\n",
    "                \"\"\"\n",
    "                ]\n",
    "\n",
    "session_id = agent.create_session(\"web-session\")\n",
    "for prompt in user_prompts:\n",
    "    print(\"\\n\"+\"=\"*50)\n",
    "    cprint(f\"Processing user query: {prompt}\", \"blue\")\n",
    "    print(\"=\"*50)\n",
    "    response = agent.create_turn(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        session_id=session_id,\n",
    "        stream=stream\n",
    "    )\n",
    "    if stream:\n",
    "        for log in EventLogger().log(response):\n",
    "            log.print()\n",
    "    else:\n",
    "        step_printer(response.steps) # print the steps of an agent's response in a formatted way. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f4147a",
   "metadata": {},
   "source": [
    "### Output Analysis\n",
    "\n",
    "Above, we can see that the ReAct agent took nearly an identical approach to the prompt chaining method above, but using a single prompt instead of a chain.\n",
    "\n",
    "1. First, the agent reasoned that it needed to generated a tool call for the `pods_log` tool included in the OpenShift MCP server and did so to generate a tool call that fetched the logs for the specified pod.\n",
    "2. Next, the agent reasoned that its next step was to query the available vector database for more information about the logs and acted using the built-in `knowledge_search` tool. \n",
    "4. Then, the agent summarized the findings from the the knowledge search step and reasoned it needed to send a slack message to share this information with the team and did so by using the `slack_post_message` tool call configured with the Slack MCP server.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3105c368",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "This tutorial demonstrates how to implement agentic RAG and MCP applications with Llama Stack. We do so by initializing an agent while giving it access to the MCP tools, and RAG tool configured with Llama Stack, then invoking the agent on the specified query. We showed that we can do this with more directed Prompt Chaining or with the more open ended ReAct pattern Please check out our other notebooks for more examples using Llama Stack."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d991b679",
   "metadata": {},
   "source": [
    "#### Any Feedback?\n",
    "\n",
    "If you have any feedback on this or any other notebook in this demo series we'd love to hear it! Please go to https://www.feedback.redhat.com/jfe/form/SV_8pQsoy0U9Ccqsvk and help us improve our demos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8c9972-9e72-46f7-a655-05912a14b702",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
